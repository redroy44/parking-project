Title         : Klasyfikator miejsc parkingowych w oparciu o głębokie sieci neuronowe.
Title Note    : Inżynieria danych - Data Science
Author        : Piotr Bandurski
Email         : bandurski.piotr@gmail.com

Bibliography  : references.bib
Package       : polski
Package       : [polish]babel
Locale        : polish

name-contents  : Spis Treści
name-references: Bibliografia
name-figure    : Rysunek
name-table     : Tabela
name-abstract  : Streszczenie


[TITLE]

&pagebreak;


~ abstract {vertical-align:bottom}
Celem niniejszej pracy było zaimplementowanie i wytrenowanie klasyfikatora miejsc parkingowych bazującego na analizie obrazu z kamery przemysłowej. Aby to osiągnąć zastosowano głębokie sieci neuronowe, które do tej pory pokazywały wysoką skuteczność w problemach analizy obrazu. Sieć neuronową zaimplementowano w języku Python, przy użyciu bibliotek Keras i Tensorflow, co umożliwiło trening sieci na GPU. Finalny model osiągnął skuteczność 99,75%, co w pełni pokazuje, moc głębokich sieci neuronowych zadaniu klasyfikacji.
~

&pagebreak;


~ Begin SidePanel
[TOC]
~ End SidePanel

&pagebreak;

~ Begin MainPanel

# Wstęp

Problem dostępu do miejsc parkingowych w centrach dużych miast jest niewątpliwie jednym z większych problemów z jakimi muszą potykać się władze współczesnych metropolii. Przy rosnącej liczbie mieszkańców miast wzrasta też liczba samochodów i kierowców, którzy chcą zaparkować swoje auta. Ze względu na ograniczoną liczbę miejsc parkingowych kierowcy tracą często po kilkanaście minut w poszukiwaniu miejsca, co powoduje nie tylko zwiększony ruch samochodów, ale też zanieczyszczenie powietrza i wzrost niezadowolenia kierowców, co z kolei może negatywnie wpływać na liczbę stłuczek i wypadków.

Jednym z rozwiązań, które mają na celu ułatwić życie kierowcom są systemy monitorujące wolne miejsca na parkingach. Mają one monitorować w czasie rzeczywistym liczbę miejsc parkingowych które są wolne oraz wyświetlać takie informacje na tablicach informacyjnych. Niestety bardzo często takie rozwiązania są dosyć drogie, a montaż systemu monitorowania wymaga ingerencji w nawierzchnię parkingu czy zamontowanie barierek na wjazdach i wyjazdach. 

# Przegląd obecnych rozwiązań

Obecne rozwiązania w monitorowaniu miejsc parkingowych można zaliczyć do trzech kategorii: monitorowanie pojazdów na wjazdach/wyjazdach, monitorowanie na podstawie sieci czujników oraz monitorowanie pojazdów za pomocą systemów wizyjnych. W niniejszej pracy skupiliśmy się na ostatnim typie rozwiązań. Ich niewątpliwą zaletą są stosunkowo niskie koszty instalacji oraz brak konieczności budowy infrastruktury komunikacyjnej jak w przypadku systemów bazujących na sieci czujników. Ponadto system wizyjny można włączyć w obecny system monitorowania parkingu.

W ciągu ostatnich lat pojawiło sie wiele publikacji badających problem monitorowania miejsc parkingowych, jednak większość z nich bazowała na starszych algorytmach analizy obrazu, które nie były oparte na głębokich sieciach neuronowych.

W niniejszej pracy autor podjął się trudu rozwiązania problemu za pomocą głębokich sieci neuronowych, które okazały się zarówno skuteczne przy rozpoznanianiu oraz wystarczająco elastyczne.

W kolejnej części pracy autor opisze pokrótce splotowe sieci neuronowe, które stoją za odrodzeniem sieci neuronowych w uczeniu maszynowym. Następnie opisze zbiór danych użyty do wytrenowania sieci neuronowej oraz opisze szczegóły implementacji i wyniki, które zostały otrzymane podczas testowania.

# Wybrana metoda klasyfikacji

Dotychczasowe próby rozwiązania problemu klasyfikacji miejsc parkingowych oparte były na klasycznych algorytmach używanych w analizie obrazów. Bazowały one na budowanych ręcznie cechach, które opisywały dany obraz.

Rewolucją, którą przyniósł rok 2012 było zastosowanie splotowych sieci neuronowych do rozpoznawania obrazów. Okazały się one bardzo skuteczne w tego typu problemach, co jeszcze lepiej pokazuje Rysunek [#fig-ilsvrc]. Prezentuje on metrykę Top-5 błędu klasyfikacji dla zbioru ImageNet, w którym należało poprawnie sklasyfikować obraz należący do jednej z 1000 klas. Znaczące obniżenie błędu klasyfikacji można zaobserwować w roku 2012 kiedy splotowe sieci neuronowe zostały wykorzystane do rozwiązania tego problemu pierwszy raz [@AlexNet]. W kolejnych latach wynik ten jeszcze się poprawiał, a w 2015 roku przekroczył wynik osiągnięty przez człowieka.

~ Figure { #fig-ilsvrc; caption: "Top-5 błędu klasyfikacji zbioru ImageNet." }
![ilsvrc]
~

[ilsvrc]: images/ilsvrc.png "ilsvrc" { width:auto; max-width:90% }

## Splotowe Sieci Neuronowe

Architektura splotowych sieci neuronowych w ogólnym ujęciu przypomina budowę tradycyjnych pełnych sieci neuronowych. Tak jak one, składają się z warstw, a ich celem jest znalezienie minimum funkcji kosztu za pomocą algorytmu propagacji wstecznej.  Różnicą jest tutaj założenie, że na wejsciu sieci podawany jest obraz. To założenie pozwala na zastosowanie pewnych rozwiązań które pozwalają na szybszą optymalizację, co z kolei pozwala na zastosowania głębszych sieci bez ryzyka ich przetrenowania.

Podstawowym elementem splotowejwybranej sieci neuronowej są: warstwa splotowa, warstwa agregująca oraz warstwa pełna. Pierwsza warstwa, jak nazwa wskazuje wykorzystuje funkcję splotu do obliczenia cech opisujących fragment obrazu. Jest ona lokalnie połączone w przeciwieństwie do warstw z tradycyjnych sieci.
Zestaw filtrów jest splatany z fragmentami obrazu, czego wynikiem jest mapa aktywacji, która znajduje fragmenty obrazu najbardziej pasujące do filtrów. Intuicyjnie filtry w drodze optymalizacji sieci uczą się optymalnie reprezentować cechy obrazu, które będą wykorzystywane do klasyfikacji.

Warstwa agregująca (max-pooling) wykorzystywana jest przede wszystkim do redukcji liczby parametrów przez wybranie wartości maksymalnej na określonym obszarze obrazu. 

W wyższych warstwach sieci wykorzystuje się znane, w pełni połączone warstwy, które są wykorzystywane do redukcji liczby parametrów i finalnej optymalizacji wartości funkcji kosztu.

Jedną z bardziej charakterystycznych architektur splotowej sieci neuronowej jest kilkukrotnie powtórzona sekwencja warstw splotowej i agregującej, która jest połączona z kilkoma warstwami pełnymi i klasyfikatorem.

## Funkcja aktywacji

Wybraną funkcją aktywacji sieci jest funkcja ReLU, czyli funkcja liniowa ograniczona zerem. Jest ona określona następującym wzorem:

~ Math { #eq-relu; caption:"Wzór funkcji ReLU" }
f(x) = \max(0, x)
~

Funkcja ta jest jedną z najczęściej stosowanych funkcji ze względu na bardzo łatwo określoną pochodną:

~ Math { #eq-relu; caption:"Wzór pochodnej funkcji ReLU" }
f'(x) = 
\begin{cases}
0, \quad x \leqslant 0 \\
1, \quad x > 0
\end{cases}
~

Negatywną cechą tej funkcji ReLU jest natomiast zjawisko zanikających gradientów. Zjawisku temu można jednak w dużym stopniu zapobiec uważnie wybierając wartości początkowe parametrów sieci neuronowej.

## Klasyfikator i funkcja kosztu

Wybranym klasyfikatorem odpowiedzialnym za predykcję klas w sieci neuronowej jest klasyfikator softmax, który stosuje entropię wzajemną jako funkcję kosztu.

Klasyfikator ten stosuje się najczęściej w przypadku klasyfikacji wielorakiej, ponieważ softmax zwraca wektor ocen dla poszczególnych klas. Ciekawą właściwością jest jego interpretacja probabilistyczna. Ponieważ wartości wektora ocen zwracanego przez klasyfikator sumują się do 1, można interpretować je jako prawdopodobieństwo, że dana próbka należy do danej klasy, co z kolei ułatwia zaobserwowanie jak bardzo pewny jest klasyfikator podczas predykcji klas.

W przypadku klasyfikacji binarnej, zwracany będzie dwuwymiarowy wektor o wartościach $[ p \quad 1-p ]$, gdzie $p$ określa prawdopodobieństwo, przynależności do pierwszej klasy. W przypadku kiedy $p \approx 0,5$ można ocenić że klasyfikator nie jest pewny, do której klasy należy dana próbka lub że klasyfikator jest źle wytrenowany.

## Algorytm optymalizacji

Wybranym algorytmem optymalizacji parametrów sieci jest algorytm Adam [@Adam]. Jest on obecnie rekomendowanym algorytmem przy uczeniu głębokich sieci neuronowych. Jego największą zaletą jest szybsze tempo optymalizacji zbiegania do minimum funkcji kosztu w porównaniu do klasycznego algorytmu gradientu stochastycznego z momentem.

## Algorytm Dropout

Algorytm Dropout [@Dropout] jest bardzo skutecznym algorytmem zapobiegającym przetrenowaniu sieci.
Jego zasadą działania jest aktywacja neuronów z pewnym prawdopodobieństwem $p$. Dzięki temu sieć musi się dostosować do treningu mając do dyspozycji mniejszą liczbę neuronów.

~ Figure { #fig-dropout; caption: "Porównanie standardowej sieci oraz sieci z zastosowaniem algorytmu dropout." }
![dropout]
~


Warto dodać, że podczas predykcji prawdopodobieństwo ustala się na wartość $1$. Można ten fakt zinterpretować jako uśrednienie predykcji zespołu (ensemble) podsieci neuronowych.

[dropout]: images/dropout.jpeg "dropout" { width:auto; max-width:90% }

# Opis zbioru danych

Wybranym zbiorem danych jest zbiór PKLot [@PKLot] przygotowany przez Uniwersytet Federalny w Paranie w Brazylii . Zbiór ten zawiera 12417 zdjęć parkingu Uniwersytecie w Paranie (UFPR) oraz parkingu Katolickiego Uniwersytetu w Paranie (PUCPR). Zdjęcia zostały zebrane w różnych warunkach pogodowych (słońce, chmury, deszcz) na przestrzeni 30 dni; zdjęcia były robione co 5 minut.
Rysunek [#fig-snapshot]. pokazuje przykładowe zdjęcie z kamery.

~ Figure { #fig-snapshot; caption: "Zdjęcie z kamery, parking PUCPR." }
![snapshot]
~

Zbiór został podzielony na 3 podzbiory reprezentujące 2 parkingi i 2 różne ujęcia dla parkingu UFPR:

* UFPR04 - 28 miejsc parkingowych
* UFPR05 - 45 miejsc parkingowych
* PUCPR - 100 miejsc parkingowych

## Opis ujęć i metadane

Do każdego zdjęcie został dołączony plik xml z metadanymi opisującymi aktualny stan parkingu. Każde miejsce parkingowe jest opisane za pomocą ID, współrzędnych na obrazie oraz obecnym stanem (wolne lub zajęte). Przykładowy opis jednego z miejsc parkingowych zamieszczony jest poniżej.

```
<space id="1" occupied="1">
  <rotatedRect>
    <center x="300" y="207" />
    <size w="55" h="32" />
    <angle d="-74" />
  </rotatedRect>
  <contour>
    <point x="278" y="230" />
    <point x="290" y="186" />
    <point x="324" y="185" />
    <point x="308" y="230" />
  </contour>
</space>
```
~ Figure { #fig-snapshot_lot; caption: "Zdjęcie z kamery z naniesionymi metadanymi." }
![snapshot_lot]
~

Na rysunku [#fig-snapshot_lot]. widać obraz parkingu z nałożonymi granicami poszczególnych miejsc parkingowych. Można zauważyć, że niektóre z nich się nakładają, co więcej, kształt samochodu zależny jest od perspektywy obrazu z kamery.

[snapshot]: images/snapshot.png "snapshot" { width:auto; max-width:90% }

[snapshot_lot]: images/snapshot_lot.png "snapshot_lot" { width:auto; max-width:90% }


## Podział zbioru danych

Ważnym udogodnieniem w zbiorze danych jest dostarczenie wraz z całymi zdjęciami z kamery, już wyekstrahowanych fragmentów miejsc parkingowych, które mogą być przesłane bezpośrednio do sieci (po zmianie rozmiaru, tak by wszystkie próbki miały ten sam rozmiar). Przykładowe próbki prezentuje rysunek [#fig-lot].

~ Figure { #fig-lot; caption: "Przykładowe próbki prezentujące wolne i zajęte miejsca parkingowe." }
![lots]
  ~

Zbiór danych jest bardzo dobrze zrównoważony tzn. próbek wolnych miejsc jest mniej więcej tyle samo co próbek miejsc zajętych, co pozwoliło na uniknięcie problemów płynących z niezbalansowania klas.

Przed przeprowadzeniem procesu treningu zbiór danych został podzielony na trzy części:

* zbiór treningowy - 50% - 325298 próbek
* zbiór walidacyjny - 30% - 219720 próbek
* zbiór testowy - 20% - 150833 próbek

W sumie zbiór ma 695851 próbek miejsc parkingowych. Warto zaznaczyć, że zbiór został podzielony wg dni, a nie pojedynczych zdjęć. Jest to ważne, żeby uniknąć sytuacji w której próbki tego samego samochodu z dwóch zdjęć trafiają do różnych zbiorów. 

[lots]: images/lots.jpg "lots" { width:auto; max-width:90% }

# Implementacja

W poniższej sekcji zostaną opisane szczegóły implementacji sieci neuronowej, która posłużyła do klasyfikacji miejsc parkingowych.
## Wybrane narzędzia

Sieć neuronowa została zaimplementowana w języku programowania Python, który jest jednym z najpopularniejszych języków stosowanych w uczeniu maszynowym. Żeby przyspieszyć proces uczenia sieci neuronowej autor zastosował bibliotekę TensorFlow [@TensorFlow], która umożliwia łatwe przeniesienie obliczeń z CPU na GPU, co pozwala na kilkukrotne przyspieszenie trenowania sieci. Przy implementacji wykorzystano również bibliotekę Keras [@Keras], która umożliwia wysokopoziomowe tworzenie głębokich sieci neuronowych. Do przetwarzania obrazu wykorzystano natomiast popularną bibliotekę OpenCV [@opencv].


## Wybrana architektura sieci neuronowej

Zaimplementowana sieć neuronowa ma stosunkowo prostą architekturę.



## Wstępne przetwarzanie obrazu

Zanim obrazy miejsc parkingowych zostały przesłane do sieci neuronowej, zostały one wstępnie przetworzone. Najpierw od wartości pikseli została odjęta średnia wartość ich jasności w każdym kanale (RGB). Proces ten nazywany jest centrowaniem.

Następnie wartości pikseli zostały znormalizowane, tak by jasność pikseli była tego samego rzędu. Efekt ten został osiągnięty przez podzielenie każdego piksela przez wartość odchylenia standardowego w całym obrazie.

## Powiększenie zbioru testującego

Jednym z zabiegów stosowanych w rozpownawaniu obrazów jest powiększanie zbioru testowego przez wygenerowanie sztucznych obrazów. Jest to możliwe na przykład za pomocą:

* lustrzanego odbicia obrazu
* zaszumienia obrazu
* powiększenia i przycięcia obrazu

zabieg ten powoduje znaczące powiększenie zbioru testowego co pozwala na lepsze wytrenowanie sieci neuronowej.

# Wyniki

Do przeprowadzenie treningu w możliwie szybkim czasie użyto maszyny z GPU NVidia Tesla K80 na serwerze Amazon Web Services. Dzięki temu trening trwał kilka razy szybciej niż na standardowej maszynie z CPU jako jednostką obliczeniową. Sieć była trenowana przez 10 epok, a osiągnęła zbieżność już po pierwszej. Finalnie osiągnęła ona skuteczność 99,75% na zbiorze testowym. Jest to zaskakująco dobry wynik biorąc pod uwagę niezbyt duży rozmiar sieci neuronowej. Rysunek [#fig-classified]. ilustruje przykładowe wyjście klasyfikatora.

~ Figure { #fig-classified; caption: "Zdjęcie z kamery z predykcjami z klasyfikatora." }
![classified]
~

Widać, że wszystkie miejsca parkingowe zostały prawidłowo sklasyfikowane.

[classified]: images/classified.png "classified" { width:auto; max-width:90% }

## Wpływ warunków pogodowych

Ważnym wymaganiem wobec klasyfikatora była odporność na różne warunki pogodowe. Mogą one wpływać na oświetlenie samochodów rzucając cień lub powodując odbicia słoneczne, które utrudniają jednoznaczne sklasfikowanie danego obrazu jako wolne lub zajęte miejsce parkingowe. Żeby sprawdzić zdolność sieci do dostosowania się do zmiennych warunków pogodowych, wybrano 3 podzbiory dla różnych warunków pogodowych (słonecznie, deszczowo, zachmurzenie). Takie podzbiory podzielono na zbiór treningowy (70%) i walidacyjny (20%) i testowy (10%). Klasyfikator wytrenowano na jednym podzbiorze i przetestowano na dwóch pozostałych. Poniżej przedstawiono macierz skuteczności klasyfikatora.

~ TableFigure { #tab-sample; caption: "Skuteczność klasyfikacji w zależności od warunków pogodowych. Klasyfikator wytrenowany na danym wierszu i przetestowany na danej kolumnie."; }
+:-{width:2cm}+:-{width:2cm}:+:-{width:2cm}:+:-{width:2cm}:+
| Słońce |0.997   |0.994   |0.991   |
|--------|--------|--------|--------|
| Deszcz |0.946   |0.997   |0.949   |
|--------|--------|--------|--------|
| Chmury |0.941   |0.985   |0.919   |
|--------|--------|--------|--------|
|        | Słońce | Deszcz | Chmury |
|--------|--------|--------|--------|
~

Pierwszą obserwacją jaka rzuca się w oczy jest obniżona skuteczność klasyfikatora przy testowaniu go w innych warunkach niż był wytrenowany. Sugeruje to, to że pełny klasyfikator dostosowuje się do różnych warunków pogodowych. Można też zauważych, że klasyfikator wytrenowany w słonecznych warunkach spisał się najlepiej.

## Uogólnienie sieci na inne parkingi

Kolejnym eksperymentem było sprawdzenie zdolności sieci neuronowej do uogólnienia na inne parkingi. Jest to szczególnie ważne przy samym użyciu sieci w komercyjnych produktach, tzn. oczekuję się żeby sieć dobrze działała na nowym parkingu przy zastosowaniu innych kamer oraz z ujęciami z innej perspektywy na parking. Do zbadania klasyfikatora pod tym kątem skorzystano z 3 podzbiorów parkingów, UFPR04, UFPR05 i PUCPR. Jeden podzbiór został wykorzystany do treningu, dwa pozostałe wykorzystano do testów. Poniżej zamieszczono maciesz skuteczności dla użytych podzbiorów.

~ TableFigure { #tab-sample; caption: "Skuteczność klasyfikacji w zależności od parkingu. Klasyfikator wytrenowany na danym wierszu i przetestowany na danej kolumnie."; }
+:-{width:2cm}+:-{width:2cm}:+:-{width:2cm}:+:-{width:2cm}:+
| PUC    |0.995   |0.896   |0.853   |
|--------|--------|--------|--------|
| UFPR04 |0.926   |0.995   |0.914   |
|--------|--------|--------|--------|
| UFPR05 |0.931   |0.825   |0.933   |
|--------|--------|--------|--------|
|        | PUC    | UFPR04 | UFPR05 |
|--------|--------|--------|--------|
~





# Wnioski

Zastosowanie splotowej sieci neuronowej do rozwiązania problemu klasyfikacji miejsc parkingowych okazało się trafnym wyborem. Przy skuteczności rzędu $99,75\%$ klasyfikator jest gotowy do fazy produktyzacji. Co więcej, zauważyć można, że już sieć neuronowa małych rozmiarów, mająca 3 warstwy splotowe, jest w stanie dostosować się do zmiennych warunków pogodowych i oświetleniowych. Niniejsza praca zaprezentowała jedynie próbkę możliwości jakie niesie zastosowanie głębokich sieci neuronowych w uczeniu maszynowym. Pewnym jest, że będą one coraz częściej wykorzystywane na rynkach komercyjnych oraz przy rozwiązywaniu codziennych problemów.

[BIB]

&pagebreak;


~ End MainPanel